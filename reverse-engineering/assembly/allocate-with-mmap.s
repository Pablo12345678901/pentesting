	# This program is an enhancement of the file 'allocate-enhanced-with-16-bytes-alignment.s'.
	# It uses 4 functions ('allocate', 'deallocate', 'deallocate_all_blocks' and 'round_up_number_to_a_specific_multiple') and shares 3 of them (all except 'round_up_number_to_a_specific_multiple') with the linked file to this one ('C' file 'use-allocate-and-deallocate-functions-with-mmap-use-in-backend.c') using such interface.
	
	# function 'allocate'
	# This function is provided one argument by the user : the size in byte(s) for the new allocation.
	# Then it will allocate an 'individual memory allocation' within a block requested with 'mmap'.
	# Precisely, on 'first call', it will :
	# 1. Round the requested size up to a 16 multiple.
	# 2. Add to it the header size rounded up to a 16 multiple.
	# 3. From this later, it will obtain the 'total requested size' of such individual memory allocation.
	# 4. Add to it the 'block header' size - also rounded up to a 16 multiple.
	# 5. Round up the final result to a 4096 multiple - that is one page-size increment on a Linux x86-64 system.
	# 6. Ask the kernel a block with 'mmap' of the specific size.
	# 7. Save the address of the first block (used during the subsequent calls - see below).
	# 8. Save the address of the block as the 'precedent block address' (used during the subsequent calls - see below).
	# 9. Then it will set the block header by filling the 'size' field.
	# 9B. The header 'next block' field is not set at each block allocation but instead, this field is set by the next block allocation if any.
	# 10. Add to such address the block header size to get the individual memory allocation address.
	# 11. Set the header of the individual memory allocation by filling the field size and setting the field 'flag in use' to '1' (0=free, 1=in use).
	# 12. Add to the individual memory allocation address the header size to obtain the address of the requested allocation - this later will be returned to the user.
	# For each 'subsequent call', it will :
	# 1. Load the address of the first block.
	# 2. Add the block header size to it to get first individual memory allocation address.
	# 3. Add to it the total requested size to see whether there is enough space within the block (by comparing it with the block end address).
	# 3B. If there is, more check will be done before allocation.
	# 3C. Else, next block will be checked - if any is available within the header field 'next block' of the current block. And repeat from step 2.
	# 3C2. If no next block is available, another block allocation will be requested and steps of 'first call' 6-12 (except 7) will be processed in addition of filling the header 'next block' field of the precedent block.
	# 4. So if there was hypothetically enough space, the header field 'in use' is checked to see if the individual memory allocation is free (=0).
	# 4B. If it is free, the header field 'size' will be checked - see step 5.
	# 4C. If it is in use, the size (written within the header) will be added to the individual memory allocation address to get next location.
	# 4C-1. Then, a check to see whether the address is still within the block is done and if not, a next block will be checked and if no next block is available, a new one will be requested and steps from 'first call' 6-12 (except 7) will be processed in addition of filling the header 'next block' field of the precedent block.
	# 4C-2. If such address is still in the block, the header field 'size' will be checked - see 5.
	# 5. The header field 'size' is compared with '0' to know whether or not a precedent allocation was done.
	# 5A. If it is '0', then no precedent allocation was done and this individual memory allocation is free and big enough so step from 11-12 from 'first call' will be processed.
	# 5B. If it is anything except '0', it will be compared with the total requested size.
	# 5B-1. If is is lower than the total requested size, next individual memory allocation will be checked and step from 3 will be repeated.
	# 5B-2. If it is bigger or equal than the total requested size, it means that this individual memory allocation was used and freed so it will be allocated with 'first call' steps 11-12 except that the 'size' field will not be updated. This could be enhanced here but was not because of my decision.
	
	# function 'deallocate'
	# This function will 'deallocate' an individual memory location provided by its only arguments from the user.
	# It will do so by modifying its header field 'flag in use' from '1' (in use) to '0' (free).
	
	# function 'deallocate_all_blocks' :
	# 1. This function will start at the first block address.
	# 2. From its header, it will obtain the size of such block as well as the next block (if any).
	# 3. Then it will deallocate the block with a 'munmap' system call.
	# 4. If there is a next block, it will load its address and repeat steps from step 2.
	# At each deallocation, a confirmation message of the block address, size and next block address will be printed.
	# At the end of all blocks deallocation, a confirmation 'end' message will be printed.

	# function 'round_up_number_to_a_specific_multiple'
	# This function has to be provided a number and a multiple and will return the number rounded up to such multiple.

# --------------------------------------------------------------------------------------------------
	
	.globl allocate, deallocate, deallocate_all_blocks
	.type round_up_number_to_a_specific_multiple, @function
	.type allocate, @function
	.type deallocate, @function
	.type deallocate_all_blocks, @function

# --------------------------------------------------------------------------------------------------
	
	# Allocate two quadword (8 bytes each) within uninitialized data section '.bss'.
	.section .bss

	# All of those variables have to be conserve from a function call to another.
	# Therefore, they cannot be on stack because stack is re-set to initial state at the end of each function call.
	# The only exception is 'next_block_address' that is dynamically computed at each function call, but for simplicity, it was set here and not on stack in order to avoid checking the offset used by 'allocate' and 'deallocate' to add new one - as well as changing the stack size (see 'X' in : 'enter $X, $0').
	
	.balign	16 # Align to 16 bytes multiple next address
first_block_address:
	.zero 8
	
	.balign	16 # Align to 16 bytes multiple next address
next_block_address:
	.zero 8

	.balign	16 # Align to 16 bytes multiple next address	
precedent_block_address:
	.zero 8
	
	.balign	16 # Align to 16 bytes multiple next address
block_size_of_header_aligned:	
	.zero 8
		
	.balign	16 # Align to 16 bytes multiple next address
individual_memory_size_of_header_aligned:
	.zero 8
	
# --------------------------------------------------------------------------------------------------
	
	.section .rodata

	# All strings are fixed so they were written within the read-only section.
	
	.balign	16 # Align to 16 bytes multiple next address
message_print_number_to_be_align:
	.ascii "Number or address to be aligned to a %d multiple : %d = %s.\n\0"
	
	.balign	16 # Align to 16 bytes multiple next address	
message_print_number_aligned:
	.ascii "Number or address       aligned to a %d multiple : %d = %s.\n\0"
	
	.balign	16 # Align to 16 bytes multiple next address	
message_block_allocation_done:
	.ascii "\nBLOCK : allocation of size %d bytes was done on address %p (end : %p) with address after header %p.\n\0"

	.balign	16 # Align to 16 bytes multiple next address	
message_individual_memory_allocation_done:
	.ascii "\nINDIVIDUAL ALLOCATION : allocation of size %d bytes was done on address %p (end : %p) with address after header %p.\n\0"

	.balign	16 # Align to 16 bytes multiple next address	
message_confirmation_end_of_all_blocks_deallocation:
	.ascii "\nEND OF DEALLOCATION : all block(s) requested with 'mmap' syscall have been deallocated with 'munmap' syscall.\n\0"

	.balign	16 # Align to 16 bytes multiple next address	
message_deallocation_block_at_address_and_size_and_next_block_address:
	.ascii "\nBLOCK : deallocation of block at address %p (%d bytes length) with next block (if any) at address %p.\n\0"

	.balign	16 # Align to 16 bytes multiple next address	
name_individual_memory_allocation_requested_size:
	.ascii "individual memory allocation requested size\0"

	.balign	16 # Align to 16 bytes multiple next address	
name_individual_memory_allocation_header:	
	.ascii "individual memory allocation header size\0"

	.balign	16 # Align to 16 bytes multiple next address	
name_individual_memory_allocation_total_size:	
	.ascii "individual memory allocation total size\0"

	.balign	16 # Align to 16 bytes multiple next address	
name_block_total_size:
	.ascii "block total size\0"
	
	.balign	16 # Align to 16 bytes multiple next address	
name_block_header_size:	
	.ascii "block header size\0"

# --------------------------------------------------------------------------------------------------
	
	.section .text

	# Local variable(s) for the function 'round_up_number_to_a_16_multiple'
	.equ LOCAL_OFFSET_ROUND_FUNCTION_ADDRESS_TO_ALIGN, -8
	.equ LOCAL_OFFSET_ROUND_FUNCTION_ADDRESS_ALIGNED, -16
	.equ LOCAL_OFFSET_ROUND_FUNCTION_NAME_OF_WHAT_IS_ALIGNED, -24
	.equ LOCAL_OFFSET_ROUND_FUNCTION_MULTIPLE_FOR_ALIGNMENT, -32
	
	.balign	16 # Align to 16 bytes multiple next address	
round_up_number_to_a_specific_multiple:
	# This function takes a number and will round it up to a specific multiple.
	# In some case, it is not an address, just a byte(s) number - in other it is an address (=also a number).
	
	# Make space on the stack for variable(s) :
	# - number to align
	# - number aligned
	# - name of what is aligned for printed message
	# - provided multiple to which round the number up
	enter $32, $0

	# Save the address provided on the stack
	movq %rdi, LOCAL_OFFSET_ROUND_FUNCTION_ADDRESS_TO_ALIGN(%rbp)
	# Save the name of what is aligned on stack for printed message
	movq %rsi, LOCAL_OFFSET_ROUND_FUNCTION_NAME_OF_WHAT_IS_ALIGNED(%rbp)
	# Save the multiple to which round up the number
	movq %rdx, LOCAL_OFFSET_ROUND_FUNCTION_MULTIPLE_FOR_ALIGNMENT(%rbp)

	# Print initial number to be aligned
	movq stdout, %rdi
	leaq message_print_number_to_be_align, %rsi
	movq LOCAL_OFFSET_ROUND_FUNCTION_MULTIPLE_FOR_ALIGNMENT(%rbp), %rdx
	movq LOCAL_OFFSET_ROUND_FUNCTION_ADDRESS_TO_ALIGN(%rbp), %rcx
	movq LOCAL_OFFSET_ROUND_FUNCTION_NAME_OF_WHAT_IS_ALIGNED(%rbp), %r8
	# No floating-point number in the variadic function arguments.
	movq $0, %rax
	call fprintf
	
	# Division
	# Load number to divide on accumulator register
	movq LOCAL_OFFSET_ROUND_FUNCTION_ADDRESS_TO_ALIGN(%rbp), %rax
	# Set %rdx to '0' for further division
	movq $0, %rdx
	# Set divisor to specific multiple
	movq LOCAL_OFFSET_ROUND_FUNCTION_MULTIPLE_FOR_ALIGNMENT(%rbp), %rdi
	# Divide address by it
	divq %rdi

	# Re-set %rax to the initial address
	movq LOCAL_OFFSET_ROUND_FUNCTION_ADDRESS_TO_ALIGN(%rbp), %rax

	# Check whether is it a multiple of such divisor (if %rdx = 0)
	cmpq $0, %rdx
	# If so - get to final part.
	je final_message_and_return

	# Else, the number is not a multiple of such divisor and there is a remainder in %rdx.
	# So the number has to rounded up to a multiple divisor.
	# So compute what has to be added to it as 'divisor - remainder'
	subq %rdx, %rdi
	
	# And add to it to initial number to get aligned one
	addq %rdi, %rax

	jmp final_message_and_return
	
	.balign	16 # Align to 16 bytes multiple next address	
final_message_and_return:
	# Save aligned address on stack
	movq %rax, LOCAL_OFFSET_ROUND_FUNCTION_ADDRESS_ALIGNED(%rbp)
	
	# Print aligned number
	movq stdout, %rdi
	leaq message_print_number_aligned, %rsi
	movq LOCAL_OFFSET_ROUND_FUNCTION_MULTIPLE_FOR_ALIGNMENT(%rbp), %rdx
	movq LOCAL_OFFSET_ROUND_FUNCTION_ADDRESS_ALIGNED(%rbp), %rcx
	movq LOCAL_OFFSET_ROUND_FUNCTION_NAME_OF_WHAT_IS_ALIGNED(%rbp), %r8
	# No floating-point number in the variadic function arguments.
	movq $0, %rax
	call fprintf

	# Return the aligned address
	movq LOCAL_OFFSET_ROUND_FUNCTION_ADDRESS_ALIGNED(%rbp), %rax 
	
	leave
	ret

# --------------------------------------------------------------------------------------------------

 	# Local variable(s) for the function 'allocate' (and other code part that it calls)
	# About blocks :
	# - the current block total size					- aligned to a 4096 bytes multiple
	# - current block examined start address 				- aligned to a 4096 bytes multiple
	# - current block examined end address 					- aligned to a 4096 bytes multiple
	# - current individual memory address examined within such block 	- aligned to a 16 bytes multiple
	# - current individual memory end address
	# - current individual memory address after its header
	# About individual memory location within blocks :
	# - requested size by user		- aligned to a 16 bytes multiple
	# - total size (header + requested 	- aligned to a 16 bytes multiple		
	.equ LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_TOTAL_SIZE_ALIGNED, -8							
	.equ LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED, -16					
	.equ LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_END_ADDRESS_ALIGNED, -24				
	.equ LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED, -32			
	.equ LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_END_ADDRESS, -40
	.equ LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_AFTER_HEADER_ALIGNED, -48		
	.equ LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_REQUESTED_SIZE_ALIGNED, -56					
	.equ LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_TOTAL_SIZE_ALIGNED, -64

	# The below value is used within the three functions 'allocate', 'deallocate' and 'deallocate_all_blocks' to set stack size in order to share the same offset for the same variables.
	.equ TOTAL_SIZE_NEEDED_FOR_STACK_ROUNDED_UP_TO_A_16_MULTIPLE, -80
	
	# Each block has a header that is composed of quadwords :
	# - the block size
	# - the next block address 
	.equ OFFSET_BLOCK_HEADER_CONTENT_SIZE, 0
	.equ OFFSET_BLOCK_HEADER_CONTENT_NEXT_BLOCK_ADDRESS, 8
	# Total header size
	.equ BLOCK_HEADER_SIZE, 16
	
	# Each individual memory allocation has a header that is composed of quadwords :
	# - first  : a flag that shows whether the block examined is in use ('1') or not ('0').
	# - second : the size of such block (= header + block content)
	.equ OFFSET_INDIVIDUAL_MEMORY_HEADER_CONTENT_FLAG_IN_USE, 0
	.equ OFFSET_INDIVIDUAL_MEMORY_HEADER_CONTENT_SIZE, 8
	# Total header size
	.equ INDIVIDUAL_MEMORY_HEADER_SIZE, 16
	
	# Those constants are used to help code reading.
	.equ MMAP_SYSCALL, 9
	.equ MUNMAP_SYSCALL, 11
	.equ ALIGNMENT_MULTIPLE_FOR_INDIVIDUAL_ADDRESS, 16
	.equ ALIGNMENT_MULTIPLE_FOR_BLOCK, 4096

	.balign	16 # Align to 16 bytes multiple next address	
allocate:
	# Make space for variable(s) on stack
	enter $TOTAL_SIZE_NEEDED_FOR_STACK_ROUNDED_UP_TO_A_16_MULTIPLE, $0
	
	# Align requested size
	#movq %rdi, %rdi # size - not needed to be updated as it is already in %rdi
	leaq name_individual_memory_allocation_requested_size, %rsi # name of what is aligned
	leaq ALIGNMENT_MULTIPLE_FOR_INDIVIDUAL_ADDRESS, %rdx
	call round_up_number_to_a_specific_multiple

	# Save the requested aligned size on the stack
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_REQUESTED_SIZE_ALIGNED(%rbp)

	# Compare the memory start with '0' to check whether the initialization was already done
	cmpq $0, first_block_address
	# If so, process to initialization
	je allocation_init
	# Else, skip the initialization
	jne allocate_init_already_done
	
	.balign	16 # Align to 16 bytes multiple next address	
allocation_init:
	# Align block header size
	leaq BLOCK_HEADER_SIZE, %rdi
	leaq name_block_header_size, %rsi
	leaq ALIGNMENT_MULTIPLE_FOR_INDIVIDUAL_ADDRESS, %rdx
	call round_up_number_to_a_specific_multiple

	# Save the block header aligned size
	movq %rax, block_size_of_header_aligned
	
	# Align individual memory header size
	leaq INDIVIDUAL_MEMORY_HEADER_SIZE, %rdi
	leaq name_individual_memory_allocation_header, %rsi
	leaq ALIGNMENT_MULTIPLE_FOR_INDIVIDUAL_ADDRESS, %rdx
	call round_up_number_to_a_specific_multiple

	# Save the header aligned size on the stack
	movq %rax, individual_memory_size_of_header_aligned
	
	# Set to '0' the precedent block address as it is the initialization and no block has been requested so far.
	movq $0, precedent_block_address

	# Set the size to align to the individual memory allocation requested one
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_REQUESTED_SIZE_ALIGNED(%rbp), %rdi
	# Add the header size to this requested size as each block is added a header at the beginning.
	addq individual_memory_size_of_header_aligned, %rdi

	# Align individual memory allocation total size - not needed as both the requested size + the header were aligned - but cool to show anyway.
	leaq name_individual_memory_allocation_total_size, %rsi
	leaq ALIGNMENT_MULTIPLE_FOR_INDIVIDUAL_ADDRESS, %rdx
	call round_up_number_to_a_specific_multiple

	# Save the total size aligned on the stack
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_TOTAL_SIZE_ALIGNED(%rbp)

	jmp allocate_request_another_block
	
	.balign	16 # Align to 16 bytes multiple next address	
allocate_init_already_done:
	# Set the size to align to the individual memory allocation requested one
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_REQUESTED_SIZE_ALIGNED(%rbp), %rdi
	# Add the header size to this requested size as each block is added a header at the beginning.
	addq individual_memory_size_of_header_aligned, %rdi

	# Align total size - not needed as both the requested size + the header were aligned - but cool to show anyway.
	leaq name_individual_memory_allocation_total_size, %rsi
	leaq ALIGNMENT_MULTIPLE_FOR_INDIVIDUAL_ADDRESS, %rdx
	call round_up_number_to_a_specific_multiple
	
	# Save the total size aligned on the stack
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_TOTAL_SIZE_ALIGNED(%rbp)
	
	# Load first block address
	movq first_block_address, %rsi
	# Set it to stack as the current block address
	movq %rsi, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp)  
	
	# Load a copy of first block address for further computation on it to get block end address
	movq first_block_address, %rdx
	# Add to it the block size to obtain block end address
	addq OFFSET_BLOCK_HEADER_CONTENT_SIZE(%rsi), %rdx
	
	# Load the address of current examined individual memory address by 
	# Load the first block address
	movq first_block_address, %rcx
	# Add the header size to the first_block_address to get first individual memory address
	addq block_size_of_header_aligned, %rcx
	# Set it to stack as the current examined individual memory address
	movq %rcx, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp)
	
	jmp allocate_loop

	.balign	16 # Align to 16 bytes multiple next address
allocate_loop:		
	# Load current block address
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rsi

	# Load a copy of current block address for further computation to get the block end address
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rdx
	# Add to it the block size to obtain current block end address
	addq OFFSET_BLOCK_HEADER_CONTENT_SIZE(%rsi), %rdx
	# Save end address on the stack
	# Even if such value is so used directly - but through the register,
	# ... this helps while debugging because the specific name given to the offset avoids to have to return to this file to know what represents the register.
	movq %rdx, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_END_ADDRESS_ALIGNED(%rbp)

	# Load the address of current examined individual memory address
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp), %rcx

	# Load a copy it current examined individual memory allocation address to %rax
	movq %rcx, %rax
	# Add the total size of requested block (header + requested, both aligned) to get the hypotethical end address of such individual allocation
	addq LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_TOTAL_SIZE_ALIGNED(%rbp), %rax
	# Check whether such hypothetical address would be beyond the block end
	cmpq %rdx, %rax
	# If so, check whether there is a next block - if not a new block will be requested with 'mmap' syscall.
	ja check_next_block
	
	# Else, such hypothetical individual memory allocation could fit within the block.
	# Load the address of current examined individual memory address
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp), %rcx
	# So check whether the current individual memory allocation is available from its 'flag' within the header
	cmpq $0, OFFSET_INDIVIDUAL_MEMORY_HEADER_CONTENT_FLAG_IN_USE(%rcx)
	
	# If not, try next individual memory allocation.
	jne try_next_individual_memory_allocation
	# Else, now we know that the individual memory allocation is available.

	# So, compare the size with '0'.
	cmpq $0, OFFSET_INDIVIDUAL_MEMORY_HEADER_CONTENT_SIZE(%rcx)
	# If the size is '0', it means that the indidivual memory allocation not set after one already set within a block
	# That is to say, a block was allocated and enough space is available within for a new individual memory allocation of the total (requested size).
	# So set the header field 'size' and allocate the such individual memory and return address after the header.
	je set_individual_memory_allocation_header_content_size_before_allocation

	# Else such individual memory allocation has a size so it was already allocated in the past but now it is free.
	# So, compare the individual memory allocation size with what was requested - maybe it is too little...
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_TOTAL_SIZE_ALIGNED(%rbp), %rax
	cmpq %rax, OFFSET_INDIVIDUAL_MEMORY_HEADER_CONTENT_SIZE(%rcx)
	# If the individual memory allocation size is below what is requested, try next one.
	jb try_next_individual_memory_allocation
	# Else the individual memory allocation available is sufficiently big for the request.
	jmp allocate_such_individual_memory

	.balign	16 # Align to 16 bytes multiple next address
set_individual_memory_allocation_header_content_size_before_allocation:
	# Load current individual memory address within a register
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp), %rcx

	# Load the total individual memory size within a register
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_TOTAL_SIZE_ALIGNED(%rbp), %rax
	# Mark its size within the header field 'size'
	movq %rax, OFFSET_INDIVIDUAL_MEMORY_HEADER_CONTENT_SIZE(%rcx)

	jmp allocate_such_individual_memory
	
	.balign	16 # Align to 16 bytes multiple next address
allocate_such_individual_memory:	
	# Load current individual memory address within a register
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp), %rcx

	# Mark it as unavailable within the header field 'flag in use'.
	movq $1, OFFSET_INDIVIDUAL_MEMORY_HEADER_CONTENT_FLAG_IN_USE(%rcx)

	# Compute the address of the individual memory allocation beyond the header
	addq individual_memory_size_of_header_aligned, %rcx

	# Save it on stack as the address of the current individual memory allocation after the header
	movq %rcx, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_AFTER_HEADER_ALIGNED(%rbp)

	# Compute the individual memory allocation end address
	# Load the individual memory allocation start address
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp), %rax
	# Add to it the total size
	addq LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_TOTAL_SIZE_ALIGNED(%rbp), %rax
	# Save the end address on stack
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_END_ADDRESS(%rbp)
	
	# Print a message with some important addresses related to the allocation - helps debugging
	movq stdout, %rdi
	leaq message_individual_memory_allocation_done, %rsi
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_TOTAL_SIZE_ALIGNED(%rbp), %rdx # Length in bytes
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp), %rcx # Individual memory allocation start address
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_END_ADDRESS(%rbp), %r8 # Individual memory allocation end address
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_AFTER_HEADER_ALIGNED(%rbp), %r9 # Individual memory allocation address after header
	# No floating-point number in the variadic function arguments.
	movq $0, %rax
	call fprintf
	
	# Load the return address of individual memory allocation after the header within '%rax' register to be returned at the end
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_AFTER_HEADER_ALIGNED(%rbp), %rax

	leave
	ret
	
	.balign	16 # Align to 16 bytes multiple next address
check_next_block:
	# Load current block address
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rsi
	
	# Check whether there is a next block by comparing its header content within the 'next block' field with '0' - set to '0' if no 'next block'	
	cmpq $0, OFFSET_BLOCK_HEADER_CONTENT_NEXT_BLOCK_ADDRESS(%rsi)
	# If no next block is available, request another block - the last block was examined
	je allocate_request_another_block
	
	# Else, load the next block address as the current block examined
	movq OFFSET_BLOCK_HEADER_CONTENT_NEXT_BLOCK_ADDRESS(%rsi), %rax
	# Save it on stack
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp)
	# Add to it the block header size to obtain the first individual memory allocation
	addq block_size_of_header_aligned, %rax
	# Save it on stack as the current individual memory allocation examined
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp)
	
	# Loop on it to check whether an individual memory allocation available fits the total (requested) size
	jmp allocate_loop
	
	.balign	16 # Align to 16 bytes multiple next address
allocate_request_another_block:
	# Load the block header size within %rax
	movq block_size_of_header_aligned, %rax
	
	# Add the total size needed for an individual memory allocation to the block header size to get the whole block size requested
	addq LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_TOTAL_SIZE_ALIGNED(%rbp), %rax

	# Align such value to a page-size increment (=4096 bytes)
	movq %rax, %rdi
	leaq name_block_total_size, %rsi
	leaq ALIGNMENT_MULTIPLE_FOR_BLOCK, %rdx
	call round_up_number_to_a_specific_multiple

	# Save the size of current block on stack
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_TOTAL_SIZE_ALIGNED(%rbp)
	
	# Request a block with 'mmap' system call
	movq $9, %rax # Set syscall number
	movq $0, %rdi 	# Let Linux choose the address of the allocation.
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_TOTAL_SIZE_ALIGNED(%rbp), %rsi # Request a specific block length
	movq $0x03, %rdx 	# Set protection flags (=file open mode) to 'read + write'.
	movq $0x22, %r10 	# Set the general flags to 'MAP_ANONYMOUS' (=no file used) and 'MAP_PRIVATE'
	movq $-1, %r8 	# No file descriptor is provided as no file will be mapped.
	movq $0, %r9		# No offset is required as no file will be mapped.
	syscall
	
	# Save the block address	
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp)
	
	# Load the block address within a register
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rsi
	# Load the block total size within another register
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_TOTAL_SIZE_ALIGNED(%rbp), %rax
	# Set its header field 'block size'
	movq %rax, OFFSET_BLOCK_HEADER_CONTENT_SIZE(%rsi)
	# No need to set the field 'next' block as it is set through next block allocation - if any.

	# Compare the 'precedent' block value with '0'.
	cmpq $0, precedent_block_address
	# If is is '0', then it is the first block allocation so adapt first block address
	je adapt_first_block_address
	# Else, fill the precedent block header field 'next block' with the value of current block that it the next one for the precedent one.
	jne adapt_header_from_precedent_block

	.balign	16 # Align to 16 bytes multiple next address
adapt_first_block_address:
	# Set the current examined block address as the first block address
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rax
	movq %rax, first_block_address

	# Set the first block as the precedent one
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rax
	movq %rax, precedent_block_address

	je allocate_request_another_block_continue

	.balign	16 # Align to 16 bytes multiple next address		
adapt_header_from_precedent_block:	
	# Load precedent block address within a register
	movq precedent_block_address, %rsi
	# Load current block address within another register
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rax
	# Adapt header of precedent block by filling the 'next block' field
	movq %rax, OFFSET_BLOCK_HEADER_CONTENT_NEXT_BLOCK_ADDRESS(%rsi)
	
	jmp allocate_request_another_block_continue

	.balign	16 # Align to 16 bytes multiple next address
allocate_request_another_block_continue:
	# Adapt precedent block address by loading to it copy of the current block address
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rax
	movq %rax, precedent_block_address
		
	# Set the current individual memory location examined to start address + block header size
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rax
	addq block_size_of_header_aligned, %rax
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp)

	# Compute the address of block end address for printed message - helps debugging
	# Load the address of block start
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rax
	# Add to it the block total size to obtain the block end address
	addq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_TOTAL_SIZE_ALIGNED(%rbp), %rax
	# Save the block end address on stack
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_END_ADDRESS_ALIGNED(%rbp)

	# Compute the first individual memory allocation address of such memory available on the block for printed message
	# Load the address of block start
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rax
	# Add the block header size to it
	addq block_size_of_header_aligned, %rax
	# Save it on stack
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp)
	
	# Print message to tell user that block allocation was done as well as important addresses about such allocation.
	movq stdout, %rdi
	leaq message_block_allocation_done, %rsi
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_TOTAL_SIZE_ALIGNED(%rbp), %rdx
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rcx # Block start address
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_END_ADDRESS_ALIGNED(%rbp), %r8 # Block end address
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp), %r9 # First individual memory allocation address (not after its header)
	# No floating-point number in the variadic function arguments.
	movq $0, %rax
	call fprintf

	# Set header of individual memory allocation and continue allocating it
	jmp set_individual_memory_allocation_header_content_size_before_allocation

	.balign	16 # Align to 16 bytes multiple next address	
try_next_individual_memory_allocation:
	# If the individual memory allocation examined before was not convenient (not available or not big enough)
	# Load the current individual memory allocation within %rsi
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp), %rsi
	# Add the size of such individual memory allocation to %rsi to get next individual memory allocation
	addq OFFSET_INDIVIDUAL_MEMORY_HEADER_CONTENT_SIZE(%rsi), %rsi
	# Save such individual memory allocation on the stack
	movq %rsi, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp)
	
	# Repeat the allocation loop = check whether next individual memory allocation is big enough
	jmp allocate_loop

	.balign	16 # Align to 16 bytes multiple next address	
try_next_block:
	# If the block examined did not have convenient individual memory allocation available
	# Load address of current block
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rsi
	# Load from its header the address of next block
	movq OFFSET_BLOCK_HEADER_CONTENT_NEXT_BLOCK_ADDRESS(%rsi), %rax
	# Adapt set such address as the one of the current block
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp)
	
	# And for the new block loaded, check all individual memory allocation available.
	jmp allocate_loop
	
	
# --------------------------------------------------------------------------------------------------

	.balign	16 # Align to 16 bytes multiple next address	
deallocate:
	# Use same local offsets here as for the 'allocate' function - useful for using same variable name (with different value)
	enter $TOTAL_SIZE_NEEDED_FOR_STACK_ROUNDED_UP_TO_A_16_MULTIPLE, $0

	# Save value on stack 
	movq %rdi, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_AFTER_HEADER_ALIGNED(%rbp)

	# Freeing an individual memory allocation is simple - we just have to mark it as available
	# Load address of individual memory allocation after the header
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_AFTER_HEADER_ALIGNED(%rbp), %rdi
	# Substract from address provided the header size to obtain the 'invidual memory allocation' start address
	subq individual_memory_size_of_header_aligned, %rdi 	
	# Save it on stack
	movq %rdi, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp)
	
	# Load address of individual memory allocation
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp), %rdi
	# Set the 'in use' flag to zero to 'free' it
	movq $0, OFFSET_INDIVIDUAL_MEMORY_HEADER_CONTENT_FLAG_IN_USE(%rdi)

	leave
	ret
	
# --------------------------------------------------------------------------------------------------

	.balign	16 # Align to 16 bytes multiple next address	
deallocate_all_blocks:
	# 1. This function will start at the first block address.
	# 2. From its header, it will obtain the size of such block as well as the next block (if any).
	# 3. Then it will deallocate the block with a 'munmap' system call.
	# 4. If there is a next block, it will load its address and repeat steps from step 2.
	# At each deallocation, a confirmation message of the block address, size and next block address will be printed.
	# At the end of all blocks deallocation, a confirmation 'end' message will be printed. 
	
	# Use same local offsets here as for the 'allocate' function - useful for using same variable name (with different value)
	enter $TOTAL_SIZE_NEEDED_FOR_STACK_ROUNDED_UP_TO_A_16_MULTIPLE, $0
	
	# Load first block address
	movq first_block_address, %rdi
	# Save it on stack
	movq %rdi, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp)
	
	jmp deallocate_block

	.balign	16 # Align to 16 bytes multiple next address	
deallocate_block:
	# Load block address within a register - same as the one used by the syscall
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rdx
	# Load the size to deallocate
	movq OFFSET_BLOCK_HEADER_CONTENT_SIZE(%rdx), %rcx
	# This step has to be done BEFORE the syscall as the data will be lost when 'munmap'ing the block.
	# Save the next block address as it will be unavailable after deallocating it.
	# It is within the block header field 'next block'
	movq OFFSET_BLOCK_HEADER_CONTENT_NEXT_BLOCK_ADDRESS(%rdx), %r8
	movq %r8, next_block_address

	# Use registers set above to print a message for confirming each deallocation.
	movq stdout, %rdi
	leaq message_deallocation_block_at_address_and_size_and_next_block_address, %rsi
	# Other arguments were already set above
	movq %rdx, %rdx # Block address
	movq %rcx, %rcx # Block size
	movq %r8, %r8 # Next block address
	# No floating-point number in the variadic function arguments.
	movq $0, %rax
	call fprintf
		
	# Set syscall number to 'munmap'
	leaq MUNMAP_SYSCALL, %rax
	# Load block address
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rdi
	# Load the size to deallocate
	movq OFFSET_BLOCK_HEADER_CONTENT_SIZE(%rdi), %rsi
	syscall
	
	jmp check_if_next_block

	.balign	16 # Align to 16 bytes multiple next address	
check_if_next_block:
	# Compare the value that was within the current block header field 'next block' with '0'
	cmpq $0, next_block_address

	# If it is '0', there is no next block so end.
	je deallocate_all_blocks_end
	
	# Else load such address as the current block and deallocate
	movq next_block_address, %rdi
	# Save it on stack
	movq %rdi, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp)
	jmp deallocate_block

	.balign	16 # Align to 16 bytes multiple next address	
deallocate_all_blocks_end:	

	# Print a confirmation message after finishing all blocks deallocation
	movq stdout, %rdi
	leaq message_confirmation_end_of_all_blocks_deallocation, %rsi
	# No floating-point number in the variadic function arguments.
	movq $0, %rax
	call fprintf
	
	leave
	ret
	
# --------------------------------------------------------------------------------------------------
	
	# Set non-executable stack ("") that contains program data "@progbits"
	.section .note.GNU-stack, "", @progbits
