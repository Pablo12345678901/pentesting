	# This program is an enhancement of the file 'allocate-enhanced-with-16-bytes-alignment.s'.
	# New features :

	# Request whole pages at a time.
	# Two level of allocation :
	# - block allocation
	# - individual memory allocations
	# Then when a request of memory is done :
	# - first it will get first block
	# - then check if within it there is any individual memory allocation available
	# - if so, allocate there
	# - else, check next block
	# - if all blocks were checked and no individual memory allocation is available, request another block.


	# Beginning :
	# No block allocated
	# Compute : requested size + header size = total size -> round up to a 4096 size
	#	- header will be added the block end address.
	# Request such block
	# 
	
	# When a request for specific size is done
	#	- add header to it
	#	- get total size
	#	- round to a block size (4096 multiple)
	
	# DEBUG TO DO



	
	# Old features that still apply : 
	# All addresses are aligned to a 16 bytes multiple as requested by standard C library functions with x86-64 architecture.
	# To do so :
	# - before each memory location as for example 'allocate' was added a directive '.balign 16' just before.
	# - each part of the allocation blocks have size rounded up to a 16 multiple with the function 'round_up_number_to_a_specific_multiple'. All of those (when aligned) are saved on the stack. To help code readibility.
	# - even the program break is rounded up to a 16 multiple with the same function. It is not needed as it is already aligned but was coded for fun. It is saved on stack too.
	# This program tries to reproduce 'malloc' and 'free' implementation.
	# It will first check whether the memory pointers ('memory_start' and 'memory_end', that represents the pointer to were a block starts and were it ends) were initialized.
	# Then, if not, it will initialize them to current 'program break'.
	# Then it will process to a loop until allocation was performed :
	# It will check whether both pointer are equal : whether all blocks were checked so far and if so, save the current program break to be returned and then move it of the total size (total size = requested + header size).
	# Else, it will check the current block composed of a header and the block content.
	# The header size if composed of two quadwords :
	# - first  : a flag that shows whether the block examined is in use ('1') or not ('0').
	# - second : the size of such block (= header + block content)
	# So, it will first check whether the block is available and if not, add its size to the current 'memory start' (start of the block) to obtain address of next block.
	# Else, it will check whether the block content size (second quadword of the header) is enough for the requested size (total size = requested + header).
	# If it is enough, it will allocate the block but setting the first quadword of the header to unavailable (=1) and return the address of the current memory_start + header size = pointer to block content.
	# Else, it will check the next block.
	# This program have to be linked with the 'C' program 'use-allocate-and-deallocate-functions.c' and then this later executed.

# --------------------------------------------------------------------------------------------------
	
	.globl allocate, deallocate
	.type allocate, @function
	.type deallocate, @function
	.type round_up_number_to_a_specific_multiple, @function

# --------------------------------------------------------------------------------------------------
	
	# Allocate two quadword (8 bytes each) within uninitialized data section '.bss'.
	.section .bss
	
	.balign	16 # Align to 16 bytes multiple next address
first_block_address:
	.zero 8

	.balign	16 # Align to 16 bytes multiple next address
block_size_of_header_aligned:	
	.zero 8
		
	.balign	16 # Align to 16 bytes multiple next address
individual_memory_size_of_header_aligned:
	.zero 8

	
# --------------------------------------------------------------------------------------------------
	
	.section .rodata
	
	.balign	16 # Align to 16 bytes multiple next address
message_print_number_to_be_align:
	.ascii "Number or address to be aligned to a %d multiple : %d = %s.\n\0"
	
	.balign	16 # Align to 16 bytes multiple next address	
message_print_number_aligned:
	.ascii "Number or address       aligned to a %d multiple : %d = %s.\n\0"
	
	.balign	16 # Align to 16 bytes multiple next address	
name_individual_memory_allocation_requested_size:
	.ascii "individual memory allocation requested size\0"

	.balign	16 # Align to 16 bytes multiple next address	
name_individual_memory_allocation_header:	
	.ascii "individual memory allocation header size\0"

	.balign	16 # Align to 16 bytes multiple next address	
name_individual_memory_allocation_total_size:	
	.ascii "individual memory allocation total size\0"

	.balign	16 # Align to 16 bytes multiple next address	
name_block_total_size:
	.ascii "block total size\0"
	
	.balign	16 # Align to 16 bytes multiple next address	
name_block_header_size:	
	.ascii "block header size\0"

	.balign	16 # Align to 16 bytes multiple next address	
message_block_allocation_done:
	.ascii "\nThe allocation of a block of size %d was done on address %d.\n"

	.balign	16 # Align to 16 bytes multiple next address	
message_debug_line_number:
	.ascii "\nDEBUG : line %d\n\0"

	
# --------------------------------------------------------------------------------------------------
	
	.section .text

# --------------------------------------------------------------------------------------------------

	.balign	16 # Align to 16 bytes multiple next address	
print_debug_message_with_line_number:
	enter $0, $0

	# Save line number as argument for the print format
	movq %rdi, %rdx
	movq stdout, %rdi
	leaq message_debug_line_number, %rsi
	# No floating-point number in the variadic function arguments.
	movq $0, %rax
	call fprintf
	
	leave
	ret
		
	# Local variable(s) for the function 'round_up_number_to_a_16_multiple'
	.equ LOCAL_OFFSET_ROUND_FUNCTION_ADDRESS_TO_ALIGN, -8
	.equ LOCAL_OFFSET_ROUND_FUNCTION_ADDRESS_ALIGNED, -16
	.equ LOCAL_OFFSET_ROUND_FUNCTION_NAME_OF_WHAT_IS_ALIGNED, -24
	.equ LOCAL_OFFSET_ROUND_FUNCTION_MULTIPLE_FOR_ALIGNMENT, -32

	.balign	16 # Align to 16 bytes multiple next address	
round_up_number_to_a_specific_multiple:
	# This function takes a number and will round it up to a specific multiple.
	# In some case, it is not an address, just a byte(s) number - in other it is an address (=also a number).
	
	# Make space on the stack for variable(s) :
	# - number to align
	# - number aligned
	# - name of what is aligned for printed message
	# - provided multiple to which round the number up
	enter $32, $0

	# Save the address provided on the stack
	movq %rdi, LOCAL_OFFSET_ROUND_FUNCTION_ADDRESS_TO_ALIGN(%rbp)
	# Save the name of what is aligned on stack for printed message
	movq %rsi, LOCAL_OFFSET_ROUND_FUNCTION_NAME_OF_WHAT_IS_ALIGNED(%rbp)
	# Save the multiple to which round up the number
	movq %rdx, LOCAL_OFFSET_ROUND_FUNCTION_MULTIPLE_FOR_ALIGNMENT(%rbp)

	# Print initial number to be aligned
	movq stdout, %rdi
	leaq message_print_number_to_be_align, %rsi
	movq LOCAL_OFFSET_ROUND_FUNCTION_MULTIPLE_FOR_ALIGNMENT(%rbp), %rdx
	movq LOCAL_OFFSET_ROUND_FUNCTION_ADDRESS_TO_ALIGN(%rbp), %rcx
	movq LOCAL_OFFSET_ROUND_FUNCTION_NAME_OF_WHAT_IS_ALIGNED(%rbp), %r8
	# No floating-point number in the variadic function arguments.
	movq $0, %rax
	call fprintf
	
	# Division
	# Load number to divide on accumulator register
	movq LOCAL_OFFSET_ROUND_FUNCTION_ADDRESS_TO_ALIGN(%rbp), %rax
	# Set %rdx to '0' for further division
	movq $0, %rdx
	# Set divisor to specific multiple
	movq LOCAL_OFFSET_ROUND_FUNCTION_MULTIPLE_FOR_ALIGNMENT(%rbp), %rdi
	# Divide address by it
	divq %rdi

	# Re-set %rax to the initial address
	movq LOCAL_OFFSET_ROUND_FUNCTION_ADDRESS_TO_ALIGN(%rbp), %rax

	# Check whether is it a multiple of such divisor (if %rdx = 0)
	cmpq $0, %rdx
	# If so - get to final part.
	je final_message_and_return

	# Else, the number is not a multiple of such divisor and there is a remainder in %rdx.
	# So the number has to rounded up to a multiple divisor.
	# So compute what has to be added to it as 'divisor - remainder'
	subq %rdx, %rdi
	
	# And add to it to initial number to get aligned one
	addq %rdi, %rax

	jmp final_message_and_return
	
	.balign	16 # Align to 16 bytes multiple next address	
final_message_and_return:
	# Save aligned address on stack
	movq %rax, LOCAL_OFFSET_ROUND_FUNCTION_ADDRESS_ALIGNED(%rbp)
	
	# Print aligned number
	movq stdout, %rdi
	leaq message_print_number_aligned, %rsi
	movq LOCAL_OFFSET_ROUND_FUNCTION_MULTIPLE_FOR_ALIGNMENT(%rbp), %rdx
	movq LOCAL_OFFSET_ROUND_FUNCTION_ADDRESS_ALIGNED(%rbp), %rcx
	movq LOCAL_OFFSET_ROUND_FUNCTION_NAME_OF_WHAT_IS_ALIGNED(%rbp), %r8
	# No floating-point number in the variadic function arguments.
	movq $0, %rax
	call fprintf

	# Return the aligned address
	movq LOCAL_OFFSET_ROUND_FUNCTION_ADDRESS_ALIGNED(%rbp), %rax 
	
	leave
	ret

# --------------------------------------------------------------------------------------------------

 	# Local variable(s) for the function 'allocate' (and other code part that it calls)
	# About blocks :
	# - the block header size						- aligned to a 16 bytes multiple
	# - the current block total size					- aligned to a 4096 bytes multiple
	# - current block examined start address 				- aligned to a 4096 bytes multiple
	# - current block examined end address 					- aligned to a 4096 bytes multiple
	# - current individual memory address examined within such block 	- aligned to a 16 bytes multiple
	# About individual memory location within blocks :
	# - requested size by user		- aligned to a 16 bytes multiple
	# - header size				- aligned to a 16 bytes multiple
	# - total size (header + requested 	- aligned to a 16 bytes multiple						# Is		Should be
	.equ LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_TOTAL_SIZE_ALIGNED, -8							# ?		on stack - computed
	.equ LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED, -16					# ?		on stack - computed each time
	.equ LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_PRECEDENT_EXAMINED_BLOCK_ADDRESS_ALIGNED, -24					# ?		on stack
	.equ LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_END_ADDRESS_ALIGNED, -32				# ?		on stack - computed
	.equ LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED, -40			# ?		on stack
	.equ LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_AFTER_HEADER_ALIGNED, -48		# ?		on stack
	.equ LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_REQUESTED_SIZE_ALIGNED, -56					# ?		on stack
	.equ LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_TOTAL_SIZE_ALIGNED, -64						# ?		on stack

	# Each block has a header that is composed of quadwords :
	# - the block size
	# - the next block address 
	.equ OFFSET_BLOCK_HEADER_CONTENT_SIZE, 0
	.equ OFFSET_BLOCK_HEADER_CONTENT_NEXT_BLOCK_ADDRESS, 8
	# Total header size
	.equ BLOCK_HEADER_SIZE, 16
	
	# Each individual memory allocation has a header that is composed of quadwords :
	# - first  : a flag that shows whether the block examined is in use ('1') or not ('0').
	# - second : the size of such block (= header + block content)
	.equ OFFSET_INDIVIDUAL_MEMORY_HEADER_CONTENT_FLAG_IN_USE, 0
	.equ OFFSET_INDIVIDUAL_MEMORY_HEADER_CONTENT_SIZE, 8
	# Total header size
	.equ INDIVIDUAL_MEMORY_HEADER_SIZE, 16
	
	# Those constants are used to help code reading.
	.equ MMAP_SYSCALL, 9
	.equ ALIGNMENT_MULTIPLE_ADDRESS, 16
	.equ ALIGNMENT_MULTIPLE_BLOCK, 4096

	.balign	16 # Align to 16 bytes multiple next address	
allocate:
	# Make space for variable(s) on stack
	enter $64, $0
	
	# Align requested size
	#movq %rdi, %rdi # size - not needed to be updated as it is already in %rdi
	leaq name_individual_memory_allocation_requested_size, %rsi # name of what is aligned
	leaq ALIGNMENT_MULTIPLE_ADDRESS, %rdx
	call round_up_number_to_a_specific_multiple

	# Save the requested aligned size on the stack
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_REQUESTED_SIZE_ALIGNED(%rbp)

	# Compare the memory start with '0' to check whether the initialization was already not done
	cmpq $0, first_block_address
	# If so, process to initialization
	je allocation_init
	# Else, skip the initialization
	jne allocate_init_already_done
	
	.balign	16 # Align to 16 bytes multiple next address	
allocation_init:
	# Align block header size
	leaq BLOCK_HEADER_SIZE, %rdi
	leaq name_block_header_size, %rsi
	leaq ALIGNMENT_MULTIPLE_ADDRESS, %rdx
	call round_up_number_to_a_specific_multiple

	# Save the block header aligned size
	movq %rax, block_size_of_header_aligned
	
	# Align individual memory header size
	leaq INDIVIDUAL_MEMORY_HEADER_SIZE, %rdi
	leaq name_individual_memory_allocation_header, %rsi
	leaq ALIGNMENT_MULTIPLE_ADDRESS, %rdx
	call round_up_number_to_a_specific_multiple

	# Save the header aligned size on the stack
	movq %rax, individual_memory_size_of_header_aligned
	
	# Set to '0' the precedent block address as it is the initialization and no block has been requested so far.
	movq $0, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_PRECEDENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp)

	# Set the size to align to the requested one
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_REQUESTED_SIZE_ALIGNED(%rbp), %rdi
	# Add the header size to this requested size as each block is added a header at the beginning.
	addq individual_memory_size_of_header_aligned, %rdi

	# Align total size - not needed as both the requested size + the header were aligned - but cool to show anyway.
	leaq name_individual_memory_allocation_total_size, %rsi
	leaq ALIGNMENT_MULTIPLE_ADDRESS, %rdx
	call round_up_number_to_a_specific_multiple

	# Save the total size aligned on the stack
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_TOTAL_SIZE_ALIGNED(%rbp)

	jmp allocate_request_another_block
	
	.balign	16 # Align to 16 bytes multiple next address	
allocate_init_already_done:
	# Set the size to align to the requested one
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_REQUESTED_SIZE_ALIGNED(%rbp), %rdi
	# Add the header size to this requested size as each block is added a header at the beginning.
	addq individual_memory_size_of_header_aligned, %rdi

	# Align total size - not needed as both the requested size + the header were aligned - but cool to show anyway.
	leaq name_individual_memory_allocation_total_size, %rsi
	leaq ALIGNMENT_MULTIPLE_ADDRESS, %rdx
	call round_up_number_to_a_specific_multiple
	
	# Save the total size aligned on the stack
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_TOTAL_SIZE_ALIGNED(%rbp)

	# Load values of the pointer to :
	# - first block address within %rsi
	# - block end within %rdx
	# - the start of current memory individual allocation examined within %rbx
	# ... within registers.
	
	# Load first block address
	movq first_block_address, %rsi
	# Set it to stack as the current block address
	movq %rsi, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp)  
	
	# Load a copy of first block address for further computation on it
	movq first_block_address, %rdx
	# Add to it the block size to obtain block end address
	addq OFFSET_BLOCK_HEADER_CONTENT_SIZE(%rsi), %rdx
	
	# Load the address of current examined individual memory address by 
	# Load the first block address
	movq first_block_address, %rcx
	# Add the header size to the first_block_address to get first individual memory address
	addq block_size_of_header_aligned, %rcx
	# Set it to stack as the current examined individual memory address
	movq %rcx, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp)
	
	jmp allocate_loop

	.balign	16 # Align to 16 bytes multiple next address
allocate_loop:	



	
	# DEBUG THE CODE IS STUCK WITHIN THIS LOOP
	movq $371, %rdi
	call print_debug_message_with_line_number





	
	# Load current block address
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rsi

	# Load a copy of current block address for further computation on it
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rdx
	# Add to it the block size to obtain current block end address
	addq OFFSET_BLOCK_HEADER_CONTENT_SIZE(%rsi), %rdx

	# Load the address of current examined individual memory address
	# Load the current block address
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rcx
	# Add the header size to the first_block_address to get first individual memory address
	addq block_size_of_header_aligned, %rcx
	
	# Check whether the end of memory was reached -> individual memory start = block end
	cmpq %rcx, %rdx
	
	# If it is the case, request another block
	je allocate_request_another_block
	
	# Else, check whether the next individual memory allocation is available from its 'flag' (OFFSET_HEADER_IN_USE(%rsi)) within the header
	cmpq $0, OFFSET_INDIVIDUAL_MEMORY_HEADER_CONTENT_FLAG_IN_USE(%rcx)
	
	# If not, try next individual memory allocation.
	jne try_next_individual_memory_allocation
	
	# Else, compare the individual memory allocation size with what was requested
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_TOTAL_SIZE_ALIGNED(%rbp), %rax
	cmpq %rax, OFFSET_INDIVIDUAL_MEMORY_HEADER_CONTENT_SIZE(%rcx)
	# If the block size is below what is requested, try next block.
	jb try_next_individual_memory_allocation
	# Else the block available is sufficiently big for the request.
	# So mark it as unavailable.
	movq $1, OFFSET_INDIVIDUAL_MEMORY_HEADER_CONTENT_FLAG_IN_USE(%rcx)
	
	# Compute the address of the individual memory allocation beyond the header
	addq individual_memory_size_of_header_aligned, %rcx

	# Save it on stack
	movq %rcx, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_AFTER_HEADER_ALIGNED(%rbp)
	
	# Adapt address of current individual memory allocation examined
	# Load the current individual memory allocation address
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp), %rax
	# Add to it the total individual memory allocation size
	addq LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_TOTAL_SIZE_ALIGNED(%rbp), %rax
	# Save it on stack
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp)

	# Load the return address of individual memory allocation after the header within '%rax' register to be returned at the end
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_AFTER_HEADER_ALIGNED(%rbp), %rax
	# No need to adapt it to new individual memory location as this will be computed at next function call.
	leave
	ret
	
	.balign	16 # Align to 16 bytes multiple next address
allocate_request_another_block:
	# Load the block header size within %rax
	movq block_size_of_header_aligned, %rax
	
	# Add the total size needed for an individual memory allocation to the block header size to get the whole block size requested
	addq LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_TOTAL_SIZE_ALIGNED(%rbp), %rax

	# Align such value to a page-size increment (=4096 bytes)
	movq %rax, %rdi
	leaq name_block_total_size, %rsi
	leaq ALIGNMENT_MULTIPLE_BLOCK, %rdx
	call round_up_number_to_a_specific_multiple

	# Save the size of current block on stack
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_TOTAL_SIZE_ALIGNED(%rbp)
	
	# Request a block with 'mmap' system call
	movq $9, %rax # Set syscall number
	movq $0, %rdi 	# Let Linux choose the address of the allocation.
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_TOTAL_SIZE_ALIGNED(%rbp), %rsi # Request a specific block length
	movq $0x03, %rdx 	# Set protection flags (=file open mode) to 'read + write'.
	movq $0x22, %r10 	# Set the general flags to 'MAP_ANONYMOUS' (=no file used) and 'MAP_PRIVATE'
	movq $-1, %r8 	# No file descriptor is provided as no file will be mapped.
	movq $0, %r9		# No offset is required as no file will be mapped.
	syscall
	
	# Save the block address	
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp)
	
	# Compare the 'precedent' block value with '0'.
	cmpq $0, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_PRECEDENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp)
	# If is is '0', then it is the first block allocation so adapt first block address
	je adapt_first_block_address
	# Else, fill the precedent block header field 'next block' with the value of current block that it the next one for the precedent one.
	jne adapt_header_from_precedent_block
	
	.balign	16 # Align to 16 bytes multiple next address		
adapt_first_block_address:
	# Set the current examined block address as the first block address
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rax
	movq %rax, first_block_address
	je allocate_request_another_block_continue
	
	.balign	16 # Align to 16 bytes multiple next address		
adapt_header_from_precedent_block:	
	# Load precedent block address within a register
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_PRECEDENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rsi
	# Load current block address within another register
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rax
	# Adapt header of precedent block by filling the 'next block' field
	movq %rax, OFFSET_BLOCK_HEADER_CONTENT_NEXT_BLOCK_ADDRESS(%rsi)
	
	jmp allocate_request_another_block_continue

	.balign	16 # Align to 16 bytes multiple next address
allocate_request_another_block_continue:
	# Adapt precedent block address by loading to it copy of the current block address
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rax
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_PRECEDENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp)
	
	# Set the end address of such block as total size + current address
	addq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_TOTAL_SIZE_ALIGNED(%rbp), %rax
	# Save current block end address on stack
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_END_ADDRESS_ALIGNED(%rbp)
	
	# Set the current individual memory location examined to start address + block header size
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rax
	addq block_size_of_header_aligned, %rax
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp)

	# Set individual memory allocation header
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp), %rsi
	movq $1, OFFSET_INDIVIDUAL_MEMORY_HEADER_CONTENT_FLAG_IN_USE(%rsi)
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_INDIVIDUAL_MEMORY_TOTAL_SIZE_ALIGNED(%rbp), %rax
	movq %rax, OFFSET_INDIVIDUAL_MEMORY_HEADER_CONTENT_SIZE(%rsi)
	
	# Compute the address of individual memory location AFTER the header
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp), %rax
	addq individual_memory_size_of_header_aligned, %rax
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_AFTER_HEADER_ALIGNED(%rbp)
	
	# Print message to tell user that block allocation was done.
	movq stdout, %rdi
	leaq message_block_allocation_done, %rsi
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_TOTAL_SIZE_ALIGNED(%rbp), %rdx
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_AFTER_HEADER_ALIGNED(%rbp), %rcx
	# No floating-point number in the variadic function arguments.
	movq $0, %rax
	call fprintf
	
	# Return the address of the individual memory location of current examined memory location after the header
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_AFTER_HEADER_ALIGNED(%rbp), %rax
	leave
	ret

	.balign	16 # Align to 16 bytes multiple next address	
try_next_individual_memory_allocation:
	# If the block examined before was not convenient (not available or not big enough)
	# Load the current individual memory allocation within %rsi
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp), %rsi
	# Add the size of such individual memory allocation to %rsi to get next individual memory allocation
	addq OFFSET_INDIVIDUAL_MEMORY_HEADER_CONTENT_SIZE(%rsi), %rsi
	# Save such individual memory allocation on the stack
	movq %rsi, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_INDIVIDUAL_MEMORY_ADDRESS_ALIGNED(%rbp)
	
	# Repeat the allocation loop = check whether next individual memory allocation is big enough
	jmp allocate_loop

	.balign	16 # Align to 16 bytes multiple next address	
try_next_block:
	# If the block examined did not have convenient individual memory allocation available
	# Load address of current block
	movq LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp), %rsi
	# Load from its header the address of next block
	movq OFFSET_BLOCK_HEADER_CONTENT_NEXT_BLOCK_ADDRESS(%rsi), %rax
	# Adapt set such address as the one of the current block
	movq %rax, LOCAL_OFFSET_ALLOCATE_FUNCTION_BLOCK_CURRENT_EXAMINED_BLOCK_ADDRESS_ALIGNED(%rbp)
	
	# And for the new block loaded, check all individual memory allocation available.
	jmp allocate_loop
	
	.balign	16 # Align to 16 bytes multiple next address
deallocate:
	enter $0, $0
	
	# Freeing an individual memory allocation is simple - we just have to mark it as available
	# Substract from address provided the header size to obtain the 'invidual memory allocation' start address
	subq individual_memory_size_of_header_aligned, %rdi 	
	# Set the 'in use' flag to zero to 'free' it
	movq $0, OFFSET_INDIVIDUAL_MEMORY_HEADER_CONTENT_FLAG_IN_USE(%rdi)

	leave
	ret
	
# --------------------------------------------------------------------------------------------------
	
	# Set non-executable stack ("") that contains program data "@progbits"
	.section .note.GNU-stack, "", @progbits
